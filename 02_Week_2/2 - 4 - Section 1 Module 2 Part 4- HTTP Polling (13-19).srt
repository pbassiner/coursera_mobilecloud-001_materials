1
00:00:00,207 --> 00:00:09,381
[MUSIC].

2
00:00:09,381 --> 00:00:15,267
A challenge with mobile devices, is that
if we use HTTP as the primary protocol for

3
00:00:15,267 --> 00:00:18,425
communicating with the cloud we run into
the

4
00:00:18,425 --> 00:00:22,390
issue that HTTP is a client driven
protocol.

5
00:00:22,390 --> 00:00:23,840
So what do I mean by this?

6
00:00:23,840 --> 00:00:29,060
Well, in all of our interactions that
we've seen, we start with a client like

7
00:00:29,060 --> 00:00:34,520
a mobile device, that initiates the
communication

8
00:00:34,520 --> 00:00:36,530
with the server by sending in a request.

9
00:00:37,830 --> 00:00:41,310
And so, the client is always driving the
communication.

10
00:00:42,820 --> 00:00:47,370
And asking for a particular resources on
the server.

11
00:00:47,370 --> 00:00:52,830
But one of the challenges we have is the
client decides

12
00:00:52,830 --> 00:00:58,780
the timing of when it goes and checks for
updates from the server related to data.

13
00:00:58,780 --> 00:01:04,500
So anything that's going to update data or
the state of the, the client.

14
00:01:04,500 --> 00:01:08,060
Is going to require the client to make the
decision about when it

15
00:01:08,060 --> 00:01:12,130
goes and actually talks to the server and
tries to retrieve new data.

16
00:01:12,130 --> 00:01:14,130
So, if you think about this if you

17
00:01:14,130 --> 00:01:18,010
have multiple clients that are interacting
with this server.

18
00:01:18,010 --> 00:01:19,600
So, let's say we have a second client,

19
00:01:22,140 --> 00:01:25,200
that's sending requests to the server.

20
00:01:25,200 --> 00:01:29,258
And the second client sends, sends a very
important message which

21
00:01:29,258 --> 00:01:33,300
we will just do a little, yo u know,
exclamation point.

22
00:01:33,300 --> 00:01:34,730
Sends a very important message to the

23
00:01:34,730 --> 00:01:37,510
server that this client needs to know
about.

24
00:01:37,510 --> 00:01:40,730
Or some update to the data that this
client

25
00:01:40,730 --> 00:01:43,730
just pulled in has shown up on the server.

26
00:01:43,730 --> 00:01:44,799
There is no way.

27
00:01:44,799 --> 00:01:45,400
.

28
00:01:45,400 --> 00:01:50,030
For the server to easily initiate
communication with the

29
00:01:50,030 --> 00:01:52,140
client to tell it to go and update that
data.

30
00:01:53,180 --> 00:01:57,440
If we use the standard request response
model for

31
00:01:57,440 --> 00:02:00,750
communicating with the cloud over HTTP,
we'll always run

32
00:02:00,750 --> 00:02:05,120
into situations where we can't have the
server push

33
00:02:05,120 --> 00:02:07,580
data that it needs to send to the client.

34
00:02:07,580 --> 00:02:11,390
At exactly the time that the client should
have it.

35
00:02:11,390 --> 00:02:15,210
So how can we design around or handle this
issue of,

36
00:02:15,210 --> 00:02:19,200
the fact that all of the communication is
driven by the client.

37
00:02:19,200 --> 00:02:23,300
The client decides when to grab the
information from the

38
00:02:23,300 --> 00:02:27,430
server, and the timing between when it
goes and pulls information.

39
00:02:28,720 --> 00:02:30,800
One way to handle this issue, is to let

40
00:02:30,800 --> 00:02:34,590
the user decide when data is fetched from
the server.

41
00:02:34,590 --> 00:02:38,450
So a common way that you'll see this done,
is you'll see a user interface,

42
00:02:38,450 --> 00:02:42,320
particularly with list views, where we
have data,

43
00:02:44,310 --> 00:02:48,340
and there is a pull down to refresh.

44
00:02:48,340 --> 00:02:53,290
So there'll be some status refresh
indicator and if you pull down.

45
00:02:55,320 --> 00:03:00,410
What's really happening is that when you
pull down far enough, the client is going

46
00:03:00,410 --> 00:03:06,270
and sending a request to the server and
then getting the response back.

47
00:03:06,270 --> 00:03:10,090
So this time that you see that little
spinner driving around.

48
00:03:10,090 --> 00:03:13,440
What's actually happening is the client is
waiting for the data

49
00:03:13,440 --> 00:03:18,480
to comeback so that it can update its list
that it's showing.

50
00:03:18,480 --> 00:03:20,910
And this can be an effective way to handle

51
00:03:20,910 --> 00:03:23,900
the issue of going and fetching data from
the server.

52
00:03:23,900 --> 00:03:27,740
You can let the user decide when they want
to update the display.

53
00:03:27,740 --> 00:03:30,928
And in many cases they will have an
appropriate.

54
00:03:30,928 --> 00:03:33,770
You know, appropriate knowledge and make
good

55
00:03:33,770 --> 00:03:36,730
decisions about when to go and update
things.

56
00:03:36,730 --> 00:03:39,370
So this is certainly one valuable
approach.

57
00:03:39,370 --> 00:03:41,930
You can do other approaches, where for
example every

58
00:03:41,930 --> 00:03:45,465
time this view is opened it automatically
updates itself.

59
00:03:45,465 --> 00:03:49,090
Or every time the app is launched, it
automatically goes

60
00:03:49,090 --> 00:03:52,280
and synchronizes its data with that that's
on the server.

61
00:03:53,300 --> 00:03:57,050
And those are all valid approaches that
use sort of an event driven model.

62
00:03:57,050 --> 00:04:01,140
Where the events are coming from user
interactions with the app.

63
00:04:01,140 --> 00:04:05,660
And the nice thing about this approach is
that the user

64
00:04:05,660 --> 00:04:09,960
isn't going to typically go and just
refresh over and over.

65
00:04:09,960 --> 00:04:12,850
Or at least for not expend, extended
periods of time.

66
00:04:12,850 --> 00:04:15,670
At some point the user is going to stop
refreshing and give up.

67
00:04:15,670 --> 00:04:18,810
And you're going to stop sending requests
to your server.

68
00:04:18,810 --> 00:04:22,340
So the user gets to kind of make the
intelligent decisions about when it

69
00:04:22,340 --> 00:04:23,900
makes sense to actually go and fetch

70
00:04:23,900 --> 00:04:25,620
something from the server and when it
doesn't.

71
00:04:26,980 --> 00:04:30,480
Another model that you can use to try to
keep the

72
00:04:30,480 --> 00:04:34,520
client up to date with information from
the server, it's called polling.

73
00:04:34,520 --> 00:04:42,340
So, the idea behind this is, the client
starts up, the server is available.

74
00:04:42,340 --> 00:04:46,000
And while the app is running, or while
some service in the app

75
00:04:46,000 --> 00:04:48,710
is running, the client, at regular

76
00:04:48,710 --> 00:04:52,260
intervals, continually requests data from
the server.

77
00:04:53,830 --> 00:04:58,030
And you'll have some time interval that is
decided by the client.

78
00:04:58,030 --> 00:05:05,760
Some time interval like T and every T
intervals time units of T, like every

79
00:05:05,760 --> 00:05:10,100
three seconds the client will go and send
a request to the server to try to refresh.

80
00:05:10,100 --> 00:05:13,690
The problem with this is that.

81
00:05:13,690 --> 00:05:17,610
You run in the situation that if you have
a client open, even if

82
00:05:17,610 --> 00:05:22,820
there is no actual data on the server for
it, the client doesn't know that.

83
00:05:22,820 --> 00:05:26,450
It just has to blindly continually end
request

84
00:05:26,450 --> 00:05:28,540
to the server hoping that it gets
something back.

85
00:05:29,600 --> 00:05:33,350
So, while you're sending all of these
requests to the server.

86
00:05:33,350 --> 00:05:36,220
You're wasting resources on your server.

87
00:05:36,220 --> 00:05:38,640
Because every time you send a request to
the server and there's

88
00:05:38,640 --> 00:05:44,980
nothing there, the server still has to
allocate resources, process the request.

89
00:05:44,980 --> 00:05:47,530
Check if anything is available for the
client.

90
00:05:47,530 --> 00:05:49,690
And then if nothing is, send back a
response.

91
00:05:49,690 --> 00:05:53,980
You're using up network resources, memory
and cpu on the server.

92
00:05:53,980 --> 00:05:55,280
And if you have lots of

93
00:05:55,280 --> 00:05:59,880
clients, they're continuously requesting
data, you're multiplying

94
00:05:59,880 --> 00:06:05,730
the traffic and the effect on your server
in terms of the resource usage.

95
00:06:05,730 --> 00:06:10,630
So, polling certainly can give you the
effect of very up to date

96
00:06:10,630 --> 00:06:14,940
results to the client, but it can come at
a very significant cost.

97
00:06:14,940 --> 00:06:18,830
To the resources that are being used up on
your server.

98
00:06:18,830 --> 00:06:24,310
Sometimes approaches are used to try to
make the client adaptively

99
00:06:24,310 --> 00:06:29,110
decide and adjust it's time interval when
it's not getting data back.

100
00:06:29,110 --> 00:06:31,640
So the idea behind this is, is that.

101
00:06:31,640 --> 00:06:34,690
If things are updating rapidly in the
server,

102
00:06:34,690 --> 00:06:36,630
then each time the client sends a request

103
00:06:36,630 --> 00:06:41,460
or every few times that the client sends a
request, it should get a response back.

104
00:06:41,460 --> 00:06:44,020
And so the adaptive approach is
essentially start

105
00:06:44,020 --> 00:06:46,440
off with a single time interval that's
short.

106
00:06:46,440 --> 00:06:51,760
So we'll go and pull it you know, every t
seconds.

107
00:06:51,760 --> 00:06:55,430
And then if a certain number of requests
come back with no updates,

108
00:06:55,430 --> 00:07:00,640
the client will automatically switch to a
new polling rate like two T.

109
00:07:00,640 --> 00:07:04,980
So it will wait twice as long to send the
next request.

110
00:07:04,980 --> 00:07:09,810
So rather then waiting six seconds, I mean
three seconds, it'll now wait six seconds.

111
00:07:09,810 --> 00:07:11,990
Similarly, if some number of requests come

112
00:07:11,990 --> 00:07:14,820
back empty, then the client will
automatically see

113
00:07:14,820 --> 00:07:19,960
it's wasting resources in the server, so
it'll switch over to a new model like 4T.

114
00:07:21,010 --> 00:07:23,910
And continue to increase and typically
it's

115
00:07:23,910 --> 00:07:28,340
an exponential increase of the time
between when,

116
00:07:28,340 --> 00:07:33,510
it receives a request a response for a
request, until it sends the next request.

117
00:07:33,510 --> 00:07:36,710
So the client can begin adaptively
tapering off

118
00:07:36,710 --> 00:07:39,270
its requests to the server, because it
sees that

119
00:07:39,270 --> 00:07:42,030
there's not a lot happening that, not a
lot

120
00:07:42,030 --> 00:07:44,120
of updates that are of interest to that
client.

121
00:07:44,120 --> 00:07:48,140
And typically, there will be some ceiling
to this update link.

122
00:07:48,140 --> 00:07:51,040
So at some point, you'll get to maybe an
hour between

123
00:07:51,040 --> 00:07:55,760
updates, and the client will no longer
update any faster than that.

124
00:07:55,760 --> 00:07:59,270
Up until the point that it gets some
results back, in which

125
00:07:59,270 --> 00:08:03,900
case that it can switch back to the more,
rapid polling rate.

126
00:08:03,900 --> 00:08:07,320
So, once you do get something back, you
can back to the lower polling rates

127
00:08:07,320 --> 00:08:11,480
and continuously check to see if things
are coming in, that you should know about.

128
00:08:11,480 --> 00:08:15,950
So, this model really tries to adapt and
improve

129
00:08:15,950 --> 00:08:19,290
the resource utilization on the server by
having a client.

130
00:08:19,290 --> 00:08:21,820
Only poll when things are happening that
it can detect.

131
00:08:24,390 --> 00:08:28,050
Another approach to handling this issue of
trying

132
00:08:28,050 --> 00:08:30,920
to get updates from the server to the
client

133
00:08:30,920 --> 00:08:33,940
when you're using HTTP, is to rely on one

134
00:08:33,940 --> 00:08:38,730
of the newer HTTP based protocols, like
web sockets.

135
00:08:38,730 --> 00:08:45,320
So with web sockets, the idea is that,
when the

136
00:08:45,320 --> 00:08:53,480
client connects to the server, it can ask
to upgrade the connection to a web socket.

137
00:08:53,480 --> 00:08:56,770
And once a web socket has been created,
the

138
00:08:56,770 --> 00:08:59,230
idea is that the client goes and sends a
request.

139
00:08:59,230 --> 00:09:02,510
It updates the connection to a web socket.

140
00:09:02,510 --> 00:09:07,030
And rather than being purely client
driven, once this web socket is

141
00:09:07,030 --> 00:09:12,620
established either party can send data to
the other one.

142
00:09:12,620 --> 00:09:15,930
So the server at any time can push data
down to

143
00:09:15,930 --> 00:09:18,849
the client, and the client can push data
down to the server.

144
00:09:19,910 --> 00:09:24,840
All of this however, depends upon the
client being connected to the server.

145
00:09:24,840 --> 00:09:27,260
Now the nice thing about web sockets are

146
00:09:27,260 --> 00:09:31,400
that, we don't necessarily incur the
message overhead that

147
00:09:31,400 --> 00:09:34,540
we typically do with each request and
response

148
00:09:34,540 --> 00:09:38,965
from a server if we're using the HTTP
protocol.

149
00:09:38,965 --> 00:09:43,330
So, normally if we send an HTTP request,
we're

150
00:09:43,330 --> 00:09:46,010
going to send all of the header data all
of

151
00:09:46,010 --> 00:09:49,700
the other information, the resource, the
URL, all of

152
00:09:49,700 --> 00:09:51,510
this stuff is going to be sent to the
server.

153
00:09:51,510 --> 00:09:55,430
And then every time the server's going to
send back the content

154
00:09:55,430 --> 00:09:58,970
type, the body, any headers that it wants
to send back.

155
00:09:58,970 --> 00:10:01,010
And there's a lot of communication
overhead.

156
00:10:01,010 --> 00:10:04,600
And if we know very specifically about the
protocol

157
00:10:04,600 --> 00:10:07,130
that we're expecting the server to speak
to us.

158
00:10:07,130 --> 00:10:12,860
We can write simpler protocol on top of
web sockets that has lower overhead.

159
00:10:12,860 --> 00:10:17,900
We can send smaller messages that don't
include all of the typical HTTP.

160
00:10:18,900 --> 00:10:21,720
Headers and other things that we need.

161
00:10:21,720 --> 00:10:23,880
We can just simply send binary messages or

162
00:10:23,880 --> 00:10:27,260
some other format back and forth in a
server.

163
00:10:27,260 --> 00:10:31,420
And so we can potentially have an increase
in efficiency.

164
00:10:31,420 --> 00:10:33,610
We can also have the ability now to have

165
00:10:33,610 --> 00:10:37,930
the server push data whenever it wants to
the client.

166
00:10:37,930 --> 00:10:39,610
So in a number of aspects, this is

167
00:10:39,610 --> 00:10:45,170
a much improved approach to just directly
using HTTP.

168
00:10:45,170 --> 00:10:48,440
The downside of web sockets with a mobile
client is we still run

169
00:10:48,440 --> 00:10:53,730
into the issue that clients are mobile in
nature and their connections drop.

170
00:10:53,730 --> 00:11:00,360
And so, a web socket can be used to push
data from the server to the client.

171
00:11:00,360 --> 00:11:03,640
But only as long as the client is
connected to the server.

172
00:11:03,640 --> 00:11:06,220
So if we do use Web Sockets.

173
00:11:06,220 --> 00:11:10,470
We have to deal with the fact that we may,
let's say for example lose cell signal.

174
00:11:12,710 --> 00:11:18,190
And then, we need the client to
automatically go and

175
00:11:18,190 --> 00:11:22,100
reconnect and then upgrade its connection
to a web socket again.

176
00:11:22,100 --> 00:11:27,130
So, if we go with a web socket type
approach, we have to deal with

177
00:11:27,130 --> 00:11:30,680
the air handling of doing the reconnect
whenever

178
00:11:30,680 --> 00:11:33,340
we notice that a connection has been
dropped.

179
00:11:33,340 --> 00:11:36,850
So we have to have our own event mechanism
and notifications

180
00:11:36,850 --> 00:11:41,630
to detect that something has happened,
we've dropped this web socket connection.

181
00:11:41,630 --> 00:11:45,880
Keep going and trying to reconnect until
we get connected again.

182
00:11:45,880 --> 00:11:50,850
And that in itself is its own sort set of
logic that you have to think about is.

183
00:11:50,850 --> 00:11:52,230
How do you decide when to reconnect?

184
00:11:52,230 --> 00:11:54,970
Do you wait until you get an even from

185
00:11:54,970 --> 00:11:57,990
Android telling you that the internet
connection has come back?

186
00:11:57,990 --> 00:11:59,842
Do you test the internet connection to see
if

187
00:11:59,842 --> 00:12:02,550
it's fast enough to support what you
want to do?

188
00:12:02,550 --> 00:12:06,380
There's a whole host of sort of logic that
has to be built in to decide.

189
00:12:06,380 --> 00:12:10,730
Or you may just regularly try at different
intervals to reconnect.

190
00:12:10,730 --> 00:12:15,340
And also what happens between if you have
changes in the client

191
00:12:15,340 --> 00:12:18,189
and changes in the server and how do you
synchronize and other things.

192
00:12:19,300 --> 00:12:21,680
So, web sockets is a nice approach.

193
00:12:21,680 --> 00:12:23,470
You just have to be cognizant that you

194
00:12:23,470 --> 00:12:26,710
have to go deal with your own reconnection
logic.

195
00:12:26,710 --> 00:12:32,660
The other issue is that web, web sockets
can be more heavy weight on a server.

196
00:12:32,660 --> 00:12:37,420
So, for, you can imagine if you have a
client that's sending HTTP requests, if

197
00:12:37,420 --> 00:12:41,880
it doesn't actually need any data, it can
let go of the connection to the server.

198
00:12:41,880 --> 00:12:44,360
And no resources are being taken up on the
server.

199
00:12:45,560 --> 00:12:48,810
With a web socket we're going to have a
persistent connection, which

200
00:12:48,810 --> 00:12:50,510
depending on how the server is

201
00:12:50,510 --> 00:12:53,980
implemented, could be substantially more
overhead.

202
00:12:53,980 --> 00:12:57,920
It may make it so that we can't support as
many simultaneous clients.

203
00:12:57,920 --> 00:13:02,140
Or it may be that the trade off in the
reduction in message overhead,

204
00:13:02,140 --> 00:13:06,590
particular for polling, is much better
with web sockets, and so we get more out.

205
00:13:06,590 --> 00:13:10,950
But, we have to be cognizant of that
keeping an open connection can have

206
00:13:10,950 --> 00:13:13,890
substantial resource impact as well, if we

207
00:13:13,890 --> 00:13:17,130
have millions or hundreds of thousands of
clients.

208
00:13:17,130 --> 00:13:19,320
It's something to consider with an
approach like this.

