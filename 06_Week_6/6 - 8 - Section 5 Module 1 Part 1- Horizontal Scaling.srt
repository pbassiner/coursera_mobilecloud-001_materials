1
00:00:00,000 --> 00:00:08,309
[MUSIC]

2
00:00:08,309 --> 00:00:12,105
So what happens when you build
the next Instagram, and suddenly you

3
00:00:12,105 --> 00:00:16,233
have a mobile application connected
to a Cloud servers that you've built

4
00:00:16,233 --> 00:00:21,710
that's getting hundreds of thousands of
users a day, or millions of users a day?

5
00:00:21,710 --> 00:00:25,500
Is your application going to be
able to handle all of that traffic?

6
00:00:25,500 --> 00:00:30,150
Are your Cloud servers, is going to
be able to scale up to support that?

7
00:00:30,150 --> 00:00:33,040
So this is a key question when
you're building Cloud servers,

8
00:00:33,040 --> 00:00:37,680
is understanding how well they scale or
grow in response to their load.

9
00:00:38,700 --> 00:00:41,499
Now there's kind of two ways
that we can go about scaling.

10
00:00:42,680 --> 00:00:47,950
One way, is we can have requests
coming in to our server, and

11
00:00:47,950 --> 00:00:52,210
if we have 10 requests we may
not need a very big server.

12
00:00:52,210 --> 00:00:58,170
But the, if we go up to 1,000 requests,
we could try to grow and

13
00:00:58,170 --> 00:01:02,620
put ourselves onto a bigger server
that has more horsepower in it.

14
00:01:02,620 --> 00:01:04,110
And then if we go up to 10,000 requests,

15
00:01:05,240 --> 00:01:08,690
we could try to grow to
an even bigger server.

16
00:01:09,710 --> 00:01:12,950
And this idea of
continually scaling up and

17
00:01:12,950 --> 00:01:16,740
getting bigger servers,
is called vertical scalability.

18
00:01:16,740 --> 00:01:19,320
But, there's a problem with this.

19
00:01:19,320 --> 00:01:24,466
And that is, at some point we're going
to reach a traffic load that just,

20
00:01:24,466 --> 00:01:28,040
there isn't going to be a machine
big enough to support it.

21
00:01:28,040 --> 00:01:31,460
It doesn't matter if you're Google or
if you're someone smaller.

22
00:01:31,460 --> 00:01:34,900
At some point it's not going
to make sense to run all of

23
00:01:34,900 --> 00:01:37,750
this load on one single computer.

24
00:01:37,750 --> 00:01:41,380
You can imagine that there's no way
on Earth that Google could run all of

25
00:01:41,380 --> 00:01:44,380
their search operations
on a single machine.

26
00:01:44,380 --> 00:01:48,260
Instead, we're always going to have
the situation where at some point,

27
00:01:48,260 --> 00:01:52,060
we're going to have to
move our applications.

28
00:01:52,060 --> 00:01:55,680
Split it and
distribute it across multiple machines.

29
00:01:55,680 --> 00:01:59,770
And so, that's what we're trying to shoot
for when we're building an application.

30
00:01:59,770 --> 00:02:00,870
We'd like to have it so

31
00:02:00,870 --> 00:02:04,870
that when we have a small amount
of load we can have one machine.

32
00:02:05,880 --> 00:02:09,780
When we grow and get more load,
we can add another machine.

33
00:02:09,780 --> 00:02:13,050
And then when we grow yet again,
we can continue adding machines.

34
00:02:13,050 --> 00:02:16,640
And we can continue adding
machines as much as we

35
00:02:16,640 --> 00:02:19,990
want to support this request load.

36
00:02:19,990 --> 00:02:24,900
And so, in this scenario what
we're doing is horizontal scaling.

37
00:02:24,900 --> 00:02:30,350
And this is really what we're looking for
when we are building Cloud service,

38
00:02:30,350 --> 00:02:35,600
is we want to build services that can
be easily be horizontally scaled.

39
00:02:35,600 --> 00:02:39,850
And what that means is,
is that if new load shows up,

40
00:02:39,850 --> 00:02:43,300
we can easily just go and
turn on another machine.

41
00:02:43,300 --> 00:02:47,240
So, if we need more capacity,
we just add a new machine.

42
00:02:47,240 --> 00:02:52,270
Now, getting horizontal scaling
right is not necessarily easy.

43
00:02:52,270 --> 00:02:54,870
You have to do a bunch of
things in your application.

44
00:02:54,870 --> 00:02:58,940
And optimize it to make sure that you
can just turn on another machine.

45
00:02:58,940 --> 00:03:00,810
And often, we'll end up in situations,

46
00:03:00,810 --> 00:03:04,290
where inefficiencies
in our code prevent us

47
00:03:04,290 --> 00:03:10,170
from actually taking advantage of the full
benefit of a new machine coming online.

48
00:03:10,170 --> 00:03:15,810
So, if we think about this as
the computing power available to us and

49
00:03:15,810 --> 00:03:21,720
how many requests we can process, so

50
00:03:21,720 --> 00:03:26,150
measured in requests per second,
let's say.

51
00:03:26,150 --> 00:03:28,700
This is how we're going to
measure our computing power.

52
00:03:28,700 --> 00:03:34,580
And this is the number of servers that
we've allocated to our application.

53
00:03:34,580 --> 00:03:40,310
What we would expect is, is that as we
allocate servers, we would automatically

54
00:03:40,310 --> 00:03:44,940
be able to have more computing power, and
thus process more requests per second.

55
00:03:44,940 --> 00:03:46,890
But, the reality is, is that

56
00:03:47,920 --> 00:03:52,330
this computing power is not directly
related to how many requests per second.

57
00:03:52,330 --> 00:03:55,672
We can process because of inefficiencies
in the way that we've does,

58
00:03:55,672 --> 00:03:57,045
designed our application.

59
00:03:57,045 --> 00:03:59,580
So we may have something
that looks like this, and

60
00:03:59,580 --> 00:04:02,960
in reality our application may
scale something like this.

61
00:04:02,960 --> 00:04:04,510
So this may be due to,

62
00:04:04,510 --> 00:04:08,180
you know, architectural design
choices that we've made.

63
00:04:08,180 --> 00:04:13,280
We may not be able to just keep adding
machines easily, and have our number of

64
00:04:13,280 --> 00:04:18,310
requests, or clients that we can
service automatically scale up.

65
00:04:18,310 --> 00:04:21,750
So, we have to realize that whenever
we go and build an application,

66
00:04:21,750 --> 00:04:26,530
the design decisions that we're making
are going to impact us at some point and

67
00:04:26,530 --> 00:04:30,810
make it so that there's a limit to
how far we can scale because of this

68
00:04:30,810 --> 00:04:35,920
inefficiency between what we really should
be able to do and what we actually can do.

69
00:04:35,920 --> 00:04:39,440
So this inefficiency here is
going to bottleneck us and

70
00:04:39,440 --> 00:04:43,970
hurt us at some point when we
scale up across multiple machines.

71
00:04:43,970 --> 00:04:48,350
One of the big considerations that we have
to deal with when we're building these

72
00:04:48,350 --> 00:04:53,630
applications, is trying to make our
application as stateless as possible.

73
00:04:53,630 --> 00:04:58,112
And the servlets or
the controllers that we're writing.

74
00:04:58,112 --> 00:05:03,740
We want to make them as easy to just
add additional machines as possible.

75
00:05:03,740 --> 00:05:07,100
Now what stateless means,
is that we're going to remember some

76
00:05:07,100 --> 00:05:10,530
information about
the conversation with the client.

77
00:05:10,530 --> 00:05:14,200
And we're going to have things like
caches, or log in information or

78
00:05:14,200 --> 00:05:17,240
other things on the server
side that are going to

79
00:05:17,240 --> 00:05:20,260
be remembered as we begin
talking with clients.

80
00:05:20,260 --> 00:05:24,050
So that is a stateful application,
if we're remembering things.

81
00:05:24,050 --> 00:05:26,990
If we have a server that's not remembering
anything about the clients it's

82
00:05:26,990 --> 00:05:29,260
talking to, it's stateless.

83
00:05:29,260 --> 00:05:33,920
So we can send, when we have a stateless
application we can send requests for

84
00:05:33,920 --> 00:05:36,020
a stateless application to any server.

85
00:05:36,020 --> 00:05:40,560
So, we can just turn on a new server and
begin sending requests to it and

86
00:05:40,560 --> 00:05:46,050
we can essentially add capacity to our
system simply by turning on new machines,

87
00:05:46,050 --> 00:05:48,870
if we have a stateless application.

88
00:05:48,870 --> 00:05:52,982
If we have a stateful application,
when we turn on new machines,

89
00:05:52,982 --> 00:05:56,380
we're going to have to
think about if we want to

90
00:05:56,380 --> 00:05:59,410
move some of our existing
clients to those other machines.

91
00:05:59,410 --> 00:06:03,400
Or we have some important state
that needs to be migrated to them.

92
00:06:03,400 --> 00:06:06,300
How do those new machines get that state?

93
00:06:06,300 --> 00:06:07,480
How do they get access to it?

94
00:06:08,590 --> 00:06:12,540
How do we decide which clients
to move to those machines and

95
00:06:12,540 --> 00:06:14,220
how do we migrate their state?

96
00:06:14,220 --> 00:06:18,120
So, it becomes much more complicated
when we have to think about turning on

97
00:06:18,120 --> 00:06:21,150
a machine and then migrating or
bootstrapping its

98
00:06:21,150 --> 00:06:25,760
state in some way to match what's already
happened on all of the other machines.

99
00:06:25,760 --> 00:06:30,980
So, statelessness is a property that
we try to achieve in our application.

100
00:06:30,980 --> 00:06:36,560
We try to have as much of the state as
possible not stored in our application so

101
00:06:36,560 --> 00:06:39,240
that we can just turn new machines on.

102
00:06:39,240 --> 00:06:42,330
But that's not always the case and
not always easy to do.

103
00:06:42,330 --> 00:06:45,680
We'd like our controllers to be
able to process any request.

104
00:06:45,680 --> 00:06:48,880
And not have to know about
things that have gone on,

105
00:06:48,880 --> 00:06:51,230
on other machines somewhere else.

106
00:06:51,230 --> 00:06:53,220
So, these are some of
the considerations and

107
00:06:53,220 --> 00:06:56,400
what we're trying to do when we're
building highly scalable applications

